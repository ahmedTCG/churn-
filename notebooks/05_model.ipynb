{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201f2b8b",
   "metadata": {},
   "source": [
    "# 05 â€” Train Model (Logistic Regression, 30-day churn)\n",
    "\n",
    "This notebook trains a **baseline churn model** on the labeled dataset.\n",
    "\n",
    "## Inputs\n",
    "- `data/processed/model_dataset_label_30d.parquet` (features + churn_label)\n",
    "\n",
    "## Outputs\n",
    "- `artifacts/churn_model_v1.joblib` (sklearn pipeline)\n",
    "- `artifacts/feature_list.json` (feature order used during training)\n",
    "- `artifacts/train_meta_v1.json` (metrics + dataset info)\n",
    "\n",
    "## Notes\n",
    "- This is a baseline model meant to be easy to interpret and deploy.\n",
    "- The pipeline standardizes numeric features and trains Logistic Regression with class balancing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import joblib\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATASET_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"model_dataset_label_30d.parquet\"\n",
    "ARTIFACT_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"DATASET_PATH:\", DATASET_PATH)\n",
    "print(\"ARTIFACT_DIR:\", ARTIFACT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be44cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled dataset\n",
    "df = pd.read_parquet(DATASET_PATH)\n",
    "print(\"dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick label sanity\n",
    "TARGET = \"churn_label\"\n",
    "ID_COL = \"external_customerkey\"\n",
    "\n",
    "print(df[TARGET].value_counts(dropna=False))\n",
    "print(\"label mean:\", float(df[TARGET].mean()))\n",
    "\n",
    "# Missingness overview\n",
    "(df.isna().mean().sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build X/y\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "X = df.drop(columns=[c for c in [ID_COL, TARGET] if c in df.columns]).copy()\n",
    "\n",
    "# Drop task-misaligned features (optional)\n",
    "DROP_FEATURES = [\"total_revenue\", \"avg_order_value\"]\n",
    "X = X.drop(columns=DROP_FEATURES, errors=\"ignore\")\n",
    "\n",
    "# Keep only numeric (safety)\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Drop zero-variance columns (safety)\n",
    "zero_std = X.columns[X.nunique(dropna=False) <= 1].tolist()\n",
    "if zero_std:\n",
    "    X = X.drop(columns=zero_std)\n",
    "    print(\"Dropped zero-std cols:\", zero_std)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "X.dtypes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (random split baseline; use timesplit eval pipeline for leakage-safe validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"train:\", X_train.shape, \"label mean:\", float(y_train.mean()))\n",
    "print(\"test :\", X_test.shape,  \"label mean:\", float(y_test.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        solver=\"liblinear\",\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate (baseline)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_50 = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "roc = roc_auc_score(y_test, y_proba)\n",
    "pr = average_precision_score(y_test, y_proba)\n",
    "\n",
    "print(\"ROC_AUC:\", roc)\n",
    "print(\"PR_AUC :\", pr)\n",
    "print(\"\\nReport @0.5:\\n\", classification_report(y_test, y_pred_50))\n",
    "confusion_matrix(y_test, y_pred_50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "MODEL_PATH = ARTIFACT_DIR / \"churn_model_v1.joblib\"\n",
    "FEATURES_PATH = ARTIFACT_DIR / \"feature_list.json\"\n",
    "META_PATH = ARTIFACT_DIR / \"train_meta_v1.json\"\n",
    "\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "\n",
    "feature_list = list(X_train.columns)\n",
    "FEATURES_PATH.write_text(json.dumps(feature_list, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "meta = {\n",
    "    \"dataset_path\": str(DATASET_PATH),\n",
    "    \"n_rows\": int(len(df)),\n",
    "    \"n_features\": int(X.shape[1]),\n",
    "    \"dropped_zero_std\": zero_std,\n",
    "    \"dropped_features\": DROP_FEATURES,\n",
    "    \"roc_auc\": float(roc),\n",
    "    \"pr_auc\": float(pr),\n",
    "    \"train_rows\": int(len(X_train)),\n",
    "    \"test_rows\": int(len(X_test)),\n",
    "    \"label_mean\": float(y.mean()),\n",
    "}\n",
    "META_PATH.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", MODEL_PATH)\n",
    "print(\"Saved:\", FEATURES_PATH)\n",
    "print(\"Saved:\", META_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
