{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 \u2014 Postprocess Churn Scores (Risk Buckets & Lists)\n",
    "\n",
    "This notebook converts **raw churn probabilities** into **business-ready outputs**.\n",
    "\n",
    "## Inputs\n",
    "- `outputs/churn_scores_v1.csv` (from inference)\n",
    "\n",
    "## Outputs\n",
    "- Scores with risk buckets\n",
    "- Top-N highest risk customers\n",
    "- Critical & high-risk customer lists\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "SCORES_PATH = PROJECT_ROOT / \"outputs\" / \"churn_scores_v1.csv\"\n",
    "\n",
    "OUT_WITH_BUCKETS = PROJECT_ROOT / \"outputs\" / \"churn_scores_v1_with_buckets.csv\"\n",
    "OUT_TOP5000 = PROJECT_ROOT / \"outputs\" / \"churn_scores_v1_top5000.csv\"\n",
    "OUT_CRITICAL = PROJECT_ROOT / \"outputs\" / \"churn_scores_v1_critical.csv\"\n",
    "OUT_HIGH = PROJECT_ROOT / \"outputs\" / \"churn_scores_v1_high.csv\"\n",
    "\n",
    "print(\"SCORES_PATH:\", SCORES_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load churn scores"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = pd.read_csv(SCORES_PATH)\n",
    "scores.shape, scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign risk buckets\n",
    "\n",
    "Risk buckets are based on churn probability:\n",
    "- **low**: < 0.50  \n",
    "- **medium**: 0.50\u20130.70  \n",
    "- **high**: 0.70\u20130.85  \n",
    "- **critical**: \u2265 0.85  \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores[\"risk_bucket\"] = pd.cut(\n",
    "    scores[\"churn_probability\"],\n",
    "    bins=[0, 0.5, 0.7, 0.85, 1.0],\n",
    "    labels=[\"low\", \"medium\", \"high\", \"critical\"],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "scores[\"risk_bucket\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by churn risk (descending)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_sorted = scores.sort_values(\n",
    "    \"churn_probability\", ascending=False\n",
    ")\n",
    "\n",
    "scores_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write outputs for operations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scores with buckets\n",
    "scores_sorted.to_csv(OUT_WITH_BUCKETS, index=False)\n",
    "\n",
    "# Top 5000 highest-risk customers\n",
    "scores_sorted.head(5000).to_csv(OUT_TOP5000, index=False)\n",
    "\n",
    "# Critical-risk customers\n",
    "scores_sorted[scores_sorted[\"risk_bucket\"] == \"critical\"].to_csv(\n",
    "    OUT_CRITICAL, index=False\n",
    ")\n",
    "\n",
    "# High-risk customers\n",
    "scores_sorted[scores_sorted[\"risk_bucket\"] == \"high\"].to_csv(\n",
    "    OUT_HIGH, index=False\n",
    ")\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\"-\", OUT_WITH_BUCKETS)\n",
    "print(\"-\", OUT_TOP5000)\n",
    "print(\"-\", OUT_CRITICAL)\n",
    "print(\"-\", OUT_HIGH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}